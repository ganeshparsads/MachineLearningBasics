{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of **[Dual Embedding Space Model for Document Ranking](https://www.microsoft.com/en-us/research/project/dual-embedding-space-model-desm/)**"
      ],
      "metadata": {
        "id": "FaGvK9e0d57-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIKbw3Llect7",
        "outputId": "4761217d-63f9-41cb-c9f7-f0a6c79354ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rank_bm25) (1.22.4)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G81d2EDVd47S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import click\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "from rank_bm25 import BM25Okapi as BM25\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search Enginer with [Word Embeddings](https://dev.to/mage_ai/how-to-build-a-search-engine-with-word-embeddings-56jd) "
      ],
      "metadata": {
        "id": "x49ZIefdexS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ranker(object):\n",
        "    def __init__(self, query_embedding, document_embedding):\n",
        "        self.query_embedding = query_embedding\n",
        "        self.document_embedding = document_embedding\n",
        "\n",
        "    def _create_mean_embedding(self, word_embeddings):\n",
        "        return np.mean(\n",
        "            word_embeddings,\n",
        "            axis=0,\n",
        "        )\n",
        "\n",
        "    def _create_max_embedding(self, word_embeddings):\n",
        "        return np.amax(\n",
        "            word_embeddings,\n",
        "            axis=0,\n",
        "        )\n",
        "\n",
        "    def _embed(self, tokens, embedding):\n",
        "        word_embeddings = np.array([embedding[token] for token in tokens if token in embedding])\n",
        "        mean_embedding = self._create_mean_embedding(word_embeddings)\n",
        "        max_embedding = self._create_max_embedding(word_embeddings)\n",
        "        embedding = np.concatenate([mean_embedding, max_embedding])\n",
        "        unit_embedding = embedding / (embedding**2).sum()**0.5\n",
        "        return unit_embedding\n",
        "\n",
        "    def rank(self, tokenized_query, tokenized_documents):\n",
        "        \"\"\"\n",
        "        Re-ranks a set of documents according to embedding distance\n",
        "        \"\"\"\n",
        "        query_embedding = self._embed(tokenized_query, self.query_embedding) # (E,)\n",
        "        document_embeddings = np.array([self._embed(document, self.document_embedding) for document in tokenized_documents]) # (N, E)\n",
        "        scores = document_embeddings.dot(query_embedding)\n",
        "        index_rankings = np.argsort(scores)[::-1]\n",
        "        return index_rankings, np.sort(scores)[::-1]"
      ],
      "metadata": {
        "id": "T4b2vTMTePY-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Retriever(object):\n",
        "    def __init__(self, documents):\n",
        "        self.corpus = documents\n",
        "        self.bm25 = BM25(self.corpus)\n",
        "\n",
        "    def query(self, tokenized_query, n=100):\n",
        "        scores = self.bm25.get_scores(tokenized_query)\n",
        "        best_docs = sorted(range(len(scores)), key=lambda i: -scores[i])[:n]\n",
        "        return best_docs, [scores[i] for i in best_docs]\n"
      ],
      "metadata": {
        "id": "ZFg7EzLme5Kg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TSVDocumentReader(object):\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "\n",
        "    @property\n",
        "    def corpus(self):\n",
        "        df = pd.read_csv(self.path, delimiter=\"\\t\", header=None)\n",
        "        return df[3].values.tolist()"
      ],
      "metadata": {
        "id": "wE6PiOr7fBIL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentReader(object):\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "\n",
        "    @property\n",
        "    def corpus(self):\n",
        "        documents = []\n",
        "        glob_path = os.path.join(self.path, \"**\")\n",
        "        for document_path in glob.glob(glob_path, recursive=True):\n",
        "            if os.path.isfile(document_path):\n",
        "                with open(document_path, 'r', encoding='ISO-8859-1') as f:\n",
        "                    documents.append(f.read())\n",
        "        return documents"
      ],
      "metadata": {
        "id": "4Rnxc2iXfCpE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(document):\n",
        "    return list(gensim.utils.tokenize(document.lower()))\n",
        "\n",
        "\n",
        "def show_scores(documents, scores, n=10):\n",
        "    for i in range(n):\n",
        "        print(\"======== RANK: {} | SCORE: {} =======\".format(i + 1, scores[i]))\n",
        "        print(documents[i])\n",
        "        print(\"\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "bJCYQn9DfER3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print('Query: \"{}\"'.format(query))\n",
        "\n",
        "    print(\"Reading documents...\", end=\"\")\n",
        "    reader = TSVDocumentReader(path)\n",
        "    documents = [doc for doc in reader.corpus]\n",
        "    print(\" [DONE]\")\n",
        "    print(\"Tokening documents...\", end=\"\")\n",
        "    corpus = [list(gensim.utils.tokenize(doc.lower())) for doc in documents]\n",
        "    tokenized_query = tokenize(query)\n",
        "    print(\" [DONE]\")\n",
        "    \n",
        "    retriever = Retriever(corpus)\n",
        "    retrieval_indexes, retrieval_scores = retriever.query(tokenized_query)\n",
        "\n",
        "    retrieved_documents = [documents[idx] for idx in retrieval_indexes]\n",
        "    print(\"======== BM25 ========\")\n",
        "    show_scores(retrieved_documents, retrieval_scores, 20)\n",
        "\n",
        "    tokenzed_retrieved_documents = [corpus[idx] for idx in retrieval_indexes]\n",
        "\n",
        "    print(\"Loading glove embeddings...\", end=\"\")\n",
        "    query_embedding = api.load('glove-wiki-gigaword-50')\n",
        "    print(\" [DONE]\")\n",
        "    ranker = Ranker(query_embedding=query_embedding, document_embedding=query_embedding)\n",
        "    ranker_indexes, ranker_scores = ranker.rank(tokenized_query, tokenzed_retrieved_documents)\n",
        "    reranked_documents = [retrieved_documents[idx] for idx in ranker_indexes]\n",
        "\n",
        "    print(\"======== Embedding ========\")\n",
        "    show_scores(reranked_documents, ranker_scores, 20)\n",
        "\n",
        "    print(\"======== Samples ========\")\n",
        "    documents = [\n",
        "        \"An investment bonanza is coming\",\n",
        "        \"Who governs a country's airspace?\",\n",
        "        \"What is a supermoon, and how noticeable is it to the naked eye?\",\n",
        "        \"What the evidence says about police body-cameras\",\n",
        "        \"Who controls Syria?\",\n",
        "    ]\n",
        "    corpus = [list(gensim.utils.tokenize(doc.lower())) for doc in documents]\n",
        "    queries = [\n",
        "        \"banking\",\n",
        "        \"astrology\",\n",
        "        \"middle east\",\n",
        "    ]\n",
        "    for query in queries:\n",
        "        tokenized_query = tokenize(query)\n",
        "        indexes, scores = ranker.rank(tokenized_query, corpus)\n",
        "        print(query)\n",
        "        for rank, index in enumerate(indexes):\n",
        "            document = documents[index]\n",
        "            print(\"Rank: {} | Top Article: {}\".format(rank, document))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "LLvKXALefK2B",
        "outputId": "b54306e7-1c0a-4d26-d136-cdfc1285ea2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bccf88649aba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Query: \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading documents...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSVDocumentReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
          ]
        }
      ]
    }
  ]
}